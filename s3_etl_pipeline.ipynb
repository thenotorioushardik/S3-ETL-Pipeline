{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For connecting to s3 bucket\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import BytesIO\n",
    "import dask.dataframe as dd\n",
    "import s3fs\n",
    "from dask import delayed\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id = \"<AWS_ACCESS_KEY_ID>\",\n",
    "    aws_secret_access_key=\"<AWS_SECRET_ACCESS_KEY>\"\n",
    ")\n",
    "\n",
    "bucket_name = \"<YOUR_BUCKET_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the contents of a folder\n",
    "\n",
    "folder_path = \"<FOLDER_PATH>/\"\n",
    "\n",
    "def list_folder_contents(bucket, folder):\n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket, Prefix=folder)\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            data = [\n",
    "                {\"File Name\": obj['Key'], \"Size (Bytes)\": obj['Size']}\n",
    "                for obj in response['Contents']\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"No contents found in folder '{folder}'.\")\n",
    "            return pd.DataFrame(columns=[\"File Name\", \"Size (Bytes)\"])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"File Name\", \"Size (Bytes)\"])\n",
    "\n",
    "folder_contents_df = list_folder_contents(bucket_name, folder_path)\n",
    "\n",
    "if not folder_contents_df.empty:\n",
    "    print(folder_contents_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Folder is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file dynamically based on extension\n",
    "\n",
    "def read_s3_file(bucket_name, s3_file_path):\n",
    "    full_path = f's3://{bucket_name}/{s3_file_path}'\n",
    "\n",
    "    if s3_file_path.endswith('.csv'):\n",
    "        dask_df = dd.read_csv(full_path, dtype=str, low_memory=False)\n",
    "    elif s3_file_path.endswith('.tsv'):\n",
    "        dask_df = dd.read_csv(full_path, sep='\\t', dtype=str, low_memory=False)\n",
    "    elif s3_file_path.endswith('.xlsx') or s3_file_path.endswith('.xls'):\n",
    "        sheet_number = 0  # Default to the first tab\n",
    "        delayed_read_excel = delayed(pd.read_excel)\n",
    "        delayed_df = delayed_read_excel(full_path, sheet_name=sheet_number)\n",
    "        dask_df = dd.from_delayed([delayed_df])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    return dask_df    \n",
    "\n",
    "def process_data_with_inferred_dtypes(dask_df):\n",
    "    sample_df = dask_df.head(n=1000, compute=True)\n",
    "    inferred_dtypes = sample_df.dtypes.to_dict()\n",
    "\n",
    "    for column, dtype in inferred_dtypes.items():\n",
    "        dask_df[column] = dask_df[column].astype(dtype)\n",
    "\n",
    "    return dask_df\n",
    "\n",
    "s3_file_path = '<S3_FILE_PATH>'\n",
    "\n",
    "s3_file_df = read_s3_file(bucket_name, s3_file_path)\n",
    "final_dask_df = process_data_with_inferred_dtypes(s3_file_df)\n",
    "\n",
    "final_dask_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For uploading files\n",
    "\n",
    "base_folder = \"<BASE_FOLDER>/\"  # Replace with your base folder\n",
    "new_folder = \"<NEW_FOLDER>/\"  # Replace with your new folder\n",
    "\n",
    "def create_folder(bucket, folder_path):\n",
    "    placeholder_key = folder_path + \".keep\"\n",
    "    s3.put_object(Bucket=bucket, Key=placeholder_key, Body=\"\")\n",
    "    print(f\"{folder_path} created\")\n",
    "\n",
    "def upload_file(bucket, folder_path, local_file_path):\n",
    "    if not os.path.isfile(local_file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_file_path}\")\n",
    "    \n",
    "    file_name = os.path.basename(local_file_path)\n",
    "    \n",
    "    s3.upload_file(local_file_path, bucket, folder_path + file_name)\n",
    "    print(f\"{file_name} uploaded to {folder_path}\")\n",
    "\n",
    "try:\n",
    "    create_folder(bucket_name, base_folder + new_folder)\n",
    "    \n",
    "    local_file_path = \"<LOCAL_FILE_PATH>\"  # Replace with your local file path\n",
    "    \n",
    "    upload_file(bucket_name, base_folder + new_folder, local_file_path)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deleting folder\n",
    "\n",
    "base_folder = \"<BASE_FOLDER>/\" \n",
    "new_folder = \"<NEW_FOLDER>/\" \n",
    "\n",
    "def delete_folder(bucket, folder_path):\n",
    "    response = s3.list_objects_v2(Bucket=bucket, Prefix=folder_path)\n",
    "    \n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            s3.delete_object(Bucket=bucket, Key=obj['Key'])\n",
    "            print(f\"Deleted: {obj['Key']}\")\n",
    "    else:\n",
    "        print(f\"No objects found in {folder_path}\")\n",
    "    \n",
    "    print(f\"Folder '{folder_path}' deleted.\")\n",
    "\n",
    "try:\n",
    "    delete_folder(bucket_name, base_folder + new_folder)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
